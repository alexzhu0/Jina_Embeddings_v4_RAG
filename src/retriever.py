#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
RAGæ£€ç´¢å¼•æ“
è´Ÿè´£æ™ºèƒ½æ£€ç´¢ã€ç»“æœæ’åºå’Œä¸Šä¸‹æ–‡æ„å»º
"""

import re
from typing import List, Dict, Tuple, Optional, Set
from dataclasses import dataclass
import logging

from data_processor import DocumentChunk
from vector_store import get_vector_store
from api_client import get_api_client

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class RetrievalResult:
    """æ£€ç´¢ç»“æœæ•°æ®ç»“æ„"""
    chunks: List[DocumentChunk]
    provinces: Set[str]
    total_chars: int
    query_type: str
    retrieval_strategy: str

class RAGRetriever:
    """RAGæ£€ç´¢å¼•æ“"""
    
    def __init__(self, vector_store=None):
        """
        åˆå§‹åŒ–æ£€ç´¢å¼•æ“
        
        Args:
            vector_store: å‘é‡å­˜å‚¨å®ä¾‹
        """
        self.vector_store = vector_store or get_vector_store()
        
        # æŸ¥è¯¢æ„å›¾å…³é”®è¯
        self.intent_keywords = {
            "all_provinces": ["æ‰€æœ‰çœä»½", "å…¨éƒ¨çœä»½", "å„çœ", "31çœ", "å…¨å›½"],
            "single_province": [],  # å°†é€šè¿‡çœä»½åç§°åŠ¨æ€è¯†åˆ«
            "comparison": ["å¯¹æ¯”", "æ¯”è¾ƒ", "å·®å¼‚", "åŒºåˆ«", "å¼‚åŒ"],
            "statistics": ["ç»Ÿè®¡", "æ•°é‡", "æ€»è®¡", "æ±‡æ€»", "åˆ†æ"],
            "targets": ["ç›®æ ‡", "ä»»åŠ¡", "é‡ç‚¹", "è®¡åˆ’", "è§„åˆ’"],
            "economic": ["ç»æµ", "GDP", "äº§ä¸š", "å‘å±•", "å¢é•¿"],
            "social": ["ç¤¾ä¼š", "æ°‘ç”Ÿ", "æ•™è‚²", "åŒ»ç–—", "å°±ä¸š"],
            "environment": ["ç¯å¢ƒ", "ç”Ÿæ€", "ç»¿è‰²", "æ±¡æŸ“", "ç¢³"]
        }
        
        # çœä»½åç§°åˆ—è¡¨ï¼ˆç”¨äºæ„å›¾è¯†åˆ«ï¼‰
        from config.config import PROVINCES, RETRIEVAL_CONFIG
        self.provinces = PROVINCES
        self.config = RETRIEVAL_CONFIG
        
        logger.info("ğŸ” RAGæ£€ç´¢å¼•æ“åˆå§‹åŒ–å®Œæˆ")
    
    def get_adjacent_chunks(self, chunk: DocumentChunk, window: int = 1) -> List[DocumentChunk]:
        """
        è·å–æŒ‡å®šæ–‡æ¡£å—çš„ç›¸é‚»å—
        
        Args:
            chunk: ç›®æ ‡æ–‡æ¡£å—
            window: å‰åçª—å£å¤§å°ï¼ˆé»˜è®¤å‰åå„1ä¸ªå—ï¼‰
            
        Returns:
            List[DocumentChunk]: ç›¸é‚»å—åˆ—è¡¨ï¼ˆä¸åŒ…å«åŸå§‹å—ï¼‰
        """
        try:
            # è·å–åŒä¸€æ–‡æ¡£çš„æ‰€æœ‰å—
            same_doc_chunks = []
            for stored_chunk in self.vector_store.chunks:
                if (stored_chunk.source == chunk.source and 
                    stored_chunk.province == chunk.province):
                    same_doc_chunks.append(stored_chunk)
            
            # æŒ‰chunk_idæ’åº
            same_doc_chunks.sort(key=lambda x: getattr(x, 'chunk_id', 0))
            
            # æ‰¾åˆ°ç›®æ ‡å—çš„ä½ç½®
            target_index = -1
            for i, stored_chunk in enumerate(same_doc_chunks):
                if (stored_chunk.content == chunk.content and 
                    stored_chunk.start_pos == chunk.start_pos):
                    target_index = i
                    break
            
            if target_index == -1:
                logger.warning(f"âš ï¸ æœªæ‰¾åˆ°ç›®æ ‡å—çš„ä½ç½®")
                return []
            
            # è·å–ç›¸é‚»å—
            adjacent_chunks = []
            start_idx = max(0, target_index - window)
            end_idx = min(len(same_doc_chunks), target_index + window + 1)
            
            for i in range(start_idx, end_idx):
                if i != target_index:  # æ’é™¤åŸå§‹å—
                    adjacent_chunks.append(same_doc_chunks[i])
            
            logger.debug(f"ğŸ”— è·å–åˆ° {len(adjacent_chunks)} ä¸ªç›¸é‚»å—")
            return adjacent_chunks
            
        except Exception as e:
            logger.warning(f"âš ï¸ è·å–ç›¸é‚»å—å¤±è´¥: {str(e)}")
            return []
    
    def identify_query_intent(self, query: str) -> Dict[str, any]:
        """
        è¯†åˆ«æŸ¥è¯¢æ„å›¾
        
        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            
        Returns:
            Dict: æŸ¥è¯¢æ„å›¾ä¿¡æ¯
        """
        intent = {
            "type": "general",
            "provinces": [],
            "topics": [],
            "scope": "general"
        }
        
        query_lower = query.lower()
        
        # æ£€æŸ¥æ˜¯å¦æŸ¥è¯¢æ‰€æœ‰çœä»½
        for keyword in self.intent_keywords["all_provinces"]:
            if keyword in query:
                intent["type"] = "all_provinces"
                intent["scope"] = "comprehensive"
                break
        
        # æ£€æŸ¥ç‰¹å®šçœä»½
        mentioned_provinces = []
        for province in self.provinces:
            if province in query:
                mentioned_provinces.append(province)
        
        if mentioned_provinces:
            intent["provinces"] = mentioned_provinces
            if len(mentioned_provinces) == 1:
                intent["type"] = "single_province"
            else:
                intent["type"] = "multi_province"
        
        # æ£€æŸ¥å¯¹æ¯”æ„å›¾
        for keyword in self.intent_keywords["comparison"]:
            if keyword in query:
                intent["type"] = "comparison"
                break
        
        # æ£€æŸ¥ç»Ÿè®¡æ„å›¾
        for keyword in self.intent_keywords["statistics"]:
            if keyword in query:
                intent["type"] = "statistics"
                break
        
        # è¯†åˆ«ä¸»é¢˜
        topics = []
        for topic, keywords in self.intent_keywords.items():
            if topic in ["targets", "economic", "social", "environment"]:
                for keyword in keywords:
                    if keyword in query:
                        topics.append(topic)
                        break
        
        intent["topics"] = topics
        
        logger.debug(f"ğŸ¯ æŸ¥è¯¢æ„å›¾: {intent}")
        return intent
    
    def retrieve_for_all_provinces(self, query: str, top_k_per_province: int = None) -> RetrievalResult:
        """
        ä¸ºæ‰€æœ‰çœä»½æ£€ç´¢ä¿¡æ¯
        
        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            top_k_per_province: æ¯ä¸ªçœä»½è¿”å›çš„å—æ•°
            
        Returns:
            RetrievalResult: æ£€ç´¢ç»“æœ
        """
        if top_k_per_province is None:
            top_k_per_province = self.config["all_provinces"]["top_k_per_province"]
            
        logger.info(f"ğŸŒ ä¸ºæ‰€æœ‰çœä»½æ£€ç´¢: {query} (æ¯çœ{top_k_per_province}å—)")
        
        all_chunks = []
        provinces_found = set()
        
        # ä¸ºæ¯ä¸ªçœä»½å•ç‹¬æ£€ç´¢
        for province in self.provinces:
            province_chunks = self.vector_store.search(
                query, 
                top_k=top_k_per_province * 4,  # ä»3å€å¢åŠ åˆ°4å€ï¼Œæœç´¢æ›´å¤šç»“æœç”¨äºè¿‡æ»¤
                province_filter=province
            )
            
            # å–å‰Nä¸ªç»“æœ
            for chunk, score in province_chunks[:top_k_per_province]:
                all_chunks.append(chunk)
                provinces_found.add(province)
        
        total_chars = sum(chunk.char_count for chunk in all_chunks)
        
        logger.info(f"âœ… æ£€ç´¢å®Œæˆ: {len(provinces_found)} ä¸ªçœä»½, {len(all_chunks)} ä¸ªå—")
        
        return RetrievalResult(
            chunks=all_chunks,
            provinces=provinces_found,
            total_chars=total_chars,
            query_type="all_provinces",
            retrieval_strategy="province_based"
        )
    
    def retrieve_for_specific_provinces(self, query: str, provinces: List[str], 
                                      top_k_per_province: int = None) -> RetrievalResult:
        """
        ä¸ºç‰¹å®šçœä»½æ£€ç´¢ä¿¡æ¯
        
        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            provinces: çœä»½åˆ—è¡¨
            top_k_per_province: æ¯ä¸ªçœä»½è¿”å›çš„å—æ•°
            
        Returns:
            RetrievalResult: æ£€ç´¢ç»“æœ
        """
        # æ ¹æ®çœä»½æ•°é‡é€‰æ‹©é…ç½®
        if top_k_per_province is None:
            if len(provinces) == 1:
                top_k_per_province = self.config["single_province"]["top_k_per_province"]
            else:
                top_k_per_province = self.config["multi_province"]["top_k_per_province"]
        
        logger.info(f"ğŸ¯ ä¸ºç‰¹å®šçœä»½æ£€ç´¢: {provinces} (æ¯çœ{top_k_per_province}å—)")
        
        all_chunks = []
        provinces_found = set()
        
        for province in provinces:
            if province not in self.provinces:
                logger.warning(f"âš ï¸ æœªçŸ¥çœä»½: {province}")
                continue
            
            province_chunks = self.vector_store.search(
                query,
                top_k=top_k_per_province * 3,  # ä»2å€å¢åŠ åˆ°3å€
                province_filter=province
            )
            
            for chunk, score in province_chunks[:top_k_per_province]:
                all_chunks.append(chunk)
                provinces_found.add(province)
        
        total_chars = sum(chunk.char_count for chunk in all_chunks)
        
        return RetrievalResult(
            chunks=all_chunks,
            provinces=provinces_found,
            total_chars=total_chars,
            query_type="specific_provinces",
            retrieval_strategy="targeted"
        )
    
    def retrieve_for_comparison(self, query: str, provinces: List[str] = None, 
                              top_k: int = None) -> RetrievalResult:
        """
        ä¸ºå¯¹æ¯”åˆ†ææ£€ç´¢ä¿¡æ¯
        
        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            provinces: è¦å¯¹æ¯”çš„çœä»½ï¼ˆå¯é€‰ï¼‰
            top_k: è¿”å›ç»“æœæ•°
            
        Returns:
            RetrievalResult: æ£€ç´¢ç»“æœ
        """
        if top_k is None:
            top_k = self.config["comparison"]["max_total"]
        
        top_k_per_province = self.config["comparison"]["top_k_per_province"]
        
        logger.info(f"âš–ï¸ å¯¹æ¯”æ£€ç´¢: {query} (æ¯çœ{top_k_per_province}å—)")
        
        if provinces:
            # å¯¹æ¯”ç‰¹å®šçœä»½
            all_chunks = []
            provinces_found = set()
            
            for province in provinces:
                province_chunks = self.vector_store.search(
                    query,
                    top_k=top_k_per_province * 3,  # ä»2å€å¢åŠ åˆ°3å€ï¼Œæœç´¢æ›´å¤šç”¨äºç­›é€‰
                    province_filter=province
                )
                
                # å–å‰Nä¸ªç»“æœ
                for chunk, score in province_chunks[:top_k_per_province]:
                    all_chunks.append(chunk)
                    provinces_found.add(province)
        else:
            # å…¨å±€å¯¹æ¯”æ£€ç´¢
            search_results = self.vector_store.search(query, top_k=top_k)
            all_chunks = [chunk for chunk, score in search_results]
            provinces_found = set(chunk.province for chunk in all_chunks)
        
        total_chars = sum(chunk.char_count for chunk in all_chunks)
        
        return RetrievalResult(
            chunks=all_chunks,
            provinces=provinces_found,
            total_chars=total_chars,
            query_type="comparison",
            retrieval_strategy="comparative"
        )
    
    def retrieve_by_topic(self, query: str, chunk_type: str = "target", 
                         top_k: int = None) -> RetrievalResult:
        """
        æŒ‰ä¸»é¢˜æ£€ç´¢ä¿¡æ¯
        
        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            chunk_type: å—ç±»å‹è¿‡æ»¤
            top_k: è¿”å›ç»“æœæ•°
            
        Returns:
            RetrievalResult: æ£€ç´¢ç»“æœ
        """
        if top_k is None:
            top_k = self.config["topic"]["top_k"]
            
        logger.info(f"ğŸ“‹ ä¸»é¢˜æ£€ç´¢: {query} (ç±»å‹: {chunk_type}, top_k={top_k})")
        
        search_results = self.vector_store.search(
            query,
            top_k=top_k,
            chunk_type_filter=chunk_type
        )
        
        all_chunks = [chunk for chunk, score in search_results]
        provinces_found = set(chunk.province for chunk in all_chunks)
        total_chars = sum(chunk.char_count for chunk in all_chunks)
        
        return RetrievalResult(
            chunks=all_chunks,
            provinces=provinces_found,
            total_chars=total_chars,
            query_type="topic",
            retrieval_strategy="topic_based"
        )
    
    def smart_retrieve(self, query: str, max_context_chars: int = None) -> RetrievalResult:
        """
        æ™ºèƒ½æ£€ç´¢ - æ ¹æ®æŸ¥è¯¢æ„å›¾é€‰æ‹©æœ€ä½³æ£€ç´¢ç­–ç•¥
        
        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            max_context_chars: æœ€å¤§ä¸Šä¸‹æ–‡å­—ç¬¦æ•°ï¼ˆå¯é€‰ï¼Œå°†æ ¹æ®æŸ¥è¯¢ç±»å‹è‡ªåŠ¨é€‰æ‹©ï¼‰
            
        Returns:
            RetrievalResult: æ£€ç´¢ç»“æœ
        """
        logger.info(f"ğŸ§  æ™ºèƒ½æ£€ç´¢: {query}")
        
        # è¯†åˆ«æŸ¥è¯¢æ„å›¾
        intent = self.identify_query_intent(query)
        
        # æ ¹æ®æ„å›¾é€‰æ‹©æ£€ç´¢ç­–ç•¥å’Œä¸Šä¸‹æ–‡é™åˆ¶
        if intent["type"] == "all_provinces":
            # æŸ¥è¯¢æ‰€æœ‰çœä»½
            result = self.retrieve_for_all_provinces(query)
            if max_context_chars is None:
                max_context_chars = self.config["all_provinces"]["max_chars"]
        
        elif intent["type"] == "single_province":
            # æŸ¥è¯¢ç‰¹å®šçœä»½
            result = self.retrieve_for_specific_provinces(query, intent["provinces"])
            if max_context_chars is None:
                max_context_chars = self.config["single_province"]["max_chars"]
        
        elif intent["type"] == "multi_province":
            # æŸ¥è¯¢å¤šä¸ªçœä»½
            result = self.retrieve_for_specific_provinces(query, intent["provinces"])
            if max_context_chars is None:
                max_context_chars = self.config["multi_province"]["max_chars"]
        
        elif intent["type"] == "comparison":
            # å¯¹æ¯”æŸ¥è¯¢
            result = self.retrieve_for_comparison(query, intent["provinces"])
            if max_context_chars is None:
                max_context_chars = self.config["comparison"]["max_chars"]
        
        elif intent["type"] == "statistics":
            # ç»Ÿè®¡æŸ¥è¯¢
            result = self.retrieve_by_topic(query, chunk_type="target")
            if max_context_chars is None:
                max_context_chars = self.config["topic"]["max_chars"]
        
        else:
            # é€šç”¨æ£€ç´¢ - å¤§å¹…å¢åŠ æ£€ç´¢æ•°é‡
            search_results = self.vector_store.search(query, top_k=60)  # ä»25å¢åŠ åˆ°60
            primary_chunks = [chunk for chunk, score in search_results]
            
            # åº”ç”¨ç›¸é‚»å—èšåˆç­–ç•¥
            enhanced_chunks = []
            seen_chunks = set()
            
            for chunk in primary_chunks:
                # æ·»åŠ åŸå§‹å—
                chunk_key = (chunk.source, chunk.start_pos, chunk.content[:50])
                if chunk_key not in seen_chunks:
                    enhanced_chunks.append(chunk)
                    seen_chunks.add(chunk_key)
                
                # è·å–ç›¸é‚»å—å¹¶æ·»åŠ 
                adjacent_chunks = self.get_adjacent_chunks(chunk, window=1)
                for adj_chunk in adjacent_chunks:
                    adj_key = (adj_chunk.source, adj_chunk.start_pos, adj_chunk.content[:50])
                    if adj_key not in seen_chunks:
                        enhanced_chunks.append(adj_chunk)
                        seen_chunks.add(adj_key)
            
            provinces_found = set(chunk.province for chunk in enhanced_chunks)
            total_chars = sum(chunk.char_count for chunk in enhanced_chunks)
            
            result = RetrievalResult(
                chunks=enhanced_chunks,
                provinces=provinces_found,
                total_chars=total_chars,
                query_type="general",
                retrieval_strategy="semantic_with_adjacent"
            )
            if max_context_chars is None:
                max_context_chars = self.config["max_contexts_per_query"]
        
        # å¦‚æœç»“æœè¿‡é•¿ï¼Œè¿›è¡Œæˆªæ–­
        if result.total_chars > max_context_chars:
            result = self._truncate_results(result, max_context_chars)
        
        logger.info(f"âœ… æ£€ç´¢å®Œæˆ: {len(result.chunks)} ä¸ªå—, {len(result.provinces)} ä¸ªçœä»½, {result.total_chars} å­—ç¬¦")
        
        return result
    
    def _truncate_results(self, result: RetrievalResult, max_chars: int) -> RetrievalResult:
        """
        æˆªæ–­æ£€ç´¢ç»“æœä»¥é€‚åº”ä¸Šä¸‹æ–‡é™åˆ¶
        
        Args:
            result: åŸå§‹æ£€ç´¢ç»“æœ
            max_chars: æœ€å¤§å­—ç¬¦æ•°
            
        Returns:
            RetrievalResult: æˆªæ–­åçš„ç»“æœ
        """
        if result.total_chars <= max_chars:
            return result
        
        logger.info(f"âœ‚ï¸ æˆªæ–­ç»“æœ: {result.total_chars} -> {max_chars} å­—ç¬¦")
        
        # æŒ‰çœä»½å¹³å‡åˆ†é…å­—ç¬¦æ•°
        if result.query_type == "all_provinces":
            chars_per_province = max_chars // len(result.provinces)
            
            truncated_chunks = []
            province_chars = {}
            
            for chunk in result.chunks:
                province = chunk.province
                if province not in province_chars:
                    province_chars[province] = 0
                
                if province_chars[province] + chunk.char_count <= chars_per_province:
                    truncated_chunks.append(chunk)
                    province_chars[province] += chunk.char_count
        else:
            # æ”¹è¿›çš„æˆªæ–­ç­–ç•¥ï¼šä¼˜å…ˆä¿ç•™ä¿¡æ¯å¯†åº¦é«˜çš„å—
            # æŒ‰å­—ç¬¦æ•°ä¸ç›¸å…³æ€§çš„ç»¼åˆè¯„åˆ†æ’åº
            def chunk_score(chunk):
                # ç»¼åˆè¯„åˆ†ï¼šå­—ç¬¦æ•°é€‚ä¸­ä¸”å†…å®¹ä¸°å¯Œçš„å—å¾—åˆ†æ›´é«˜
                char_score = min(chunk.char_count / 500, 2.0)  # 500å­—ç¬¦å·¦å³å¾—åˆ†æœ€é«˜
                content_score = len(chunk.content.split()) / 100  # è¯æ•°è¶Šå¤šå¾—åˆ†è¶Šé«˜
                return char_score + content_score
            
            sorted_chunks = sorted(result.chunks, key=chunk_score, reverse=True)
            
            truncated_chunks = []
            current_chars = 0
            
            for chunk in sorted_chunks:
                if current_chars + chunk.char_count <= max_chars:
                    truncated_chunks.append(chunk)
                    current_chars += chunk.char_count
                else:
                    # å¦‚æœè¿˜æœ‰ç©ºé—´ï¼Œå°è¯•æˆªå–éƒ¨åˆ†å†…å®¹
                    remaining_chars = max_chars - current_chars
                    if remaining_chars > 200:  # è‡³å°‘ä¿ç•™200å­—ç¬¦æ‰æœ‰æ„ä¹‰
                        truncated_content = chunk.content[:remaining_chars-50] + "..."
                        truncated_chunk = DocumentChunk(
                            id=chunk.id + "_truncated",
                            province=chunk.province,
                            content=truncated_content,
                            chunk_type=chunk.chunk_type,
                            metadata=chunk.metadata,
                            char_count=len(truncated_content),
                            source=chunk.source,
                            start_pos=chunk.start_pos,
                            end_pos=chunk.start_pos + len(truncated_content),
                            chunk_id=chunk.chunk_id
                        )
                        truncated_chunks.append(truncated_chunk)
                    break
        
        return RetrievalResult(
            chunks=truncated_chunks,
            provinces=set(chunk.province for chunk in truncated_chunks),
            total_chars=sum(chunk.char_count for chunk in truncated_chunks),
            query_type=result.query_type,
            retrieval_strategy=result.retrieval_strategy + "_truncated"
        )
    
    def format_context(self, result: RetrievalResult) -> str:
        """
        æ ¼å¼åŒ–æ£€ç´¢ç»“æœä¸ºä¸Šä¸‹æ–‡æ–‡æœ¬
        
        Args:
            result: æ£€ç´¢ç»“æœ
            
        Returns:
            str: æ ¼å¼åŒ–çš„ä¸Šä¸‹æ–‡æ–‡æœ¬
        """
        if not result.chunks:
            return "æœªæ‰¾åˆ°ç›¸å…³ä¿¡æ¯ã€‚"
        
        context_parts = []
        
        # æŒ‰çœä»½åˆ†ç»„
        province_chunks = {}
        for chunk in result.chunks:
            province = chunk.province
            if province not in province_chunks:
                province_chunks[province] = []
            province_chunks[province].append(chunk)
        
        # æ ¼å¼åŒ–æ¯ä¸ªçœä»½çš„ä¿¡æ¯
        for province, chunks in province_chunks.items():
            context_parts.append(f"\n=== {province} ===")
            
            for chunk in chunks:
                # ç®€åŒ–å†…å®¹ï¼Œç§»é™¤å¤šä½™çš„æ¢è¡Œå’Œç©ºæ ¼
                content = re.sub(r'\s+', ' ', chunk.content.strip())
                context_parts.append(content)
        
        context = "\n".join(context_parts)
        
        logger.debug(f"ğŸ“ ä¸Šä¸‹æ–‡æ ¼å¼åŒ–å®Œæˆ: {len(context)} å­—ç¬¦")
        
        return context

# å…¨å±€æ£€ç´¢å™¨å®ä¾‹
_retriever = None

def get_retriever() -> RAGRetriever:
    """è·å–å…¨å±€æ£€ç´¢å™¨å®ä¾‹"""
    global _retriever
    if _retriever is None:
        _retriever = RAGRetriever()
    return _retriever

 