#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
ç»“æœèšåˆå™¨
è´Ÿè´£å¤šæ¬¡æŸ¥è¯¢ç»“æœçš„åˆå¹¶ã€å»é‡ã€æ ¼å¼åŒ–å’Œä¼˜åŒ–
"""

import re
from typing import List, Dict, Any, Set, Tuple
from dataclasses import dataclass
import logging

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class AggregatedResult:
    """èšåˆç»“æœæ•°æ®ç»“æ„"""
    content: str
    provinces: List[str]
    total_targets: int
    format_type: str
    processing_stats: Dict[str, Any]

class ResultAggregator:
    """ç»“æœèšåˆå™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–ç»“æœèšåˆå™¨"""
        
        # çœä»½åˆ«åæ˜ å°„ï¼ˆç”¨äºå»é‡å’Œæ ‡å‡†åŒ–ï¼‰
        self.province_aliases = {
            "äº¬": "åŒ—äº¬", "æ´¥": "å¤©æ´¥", "å†€": "æ²³åŒ—", "æ™‹": "å±±è¥¿", "è’™": "å†…è’™å¤",
            "è¾½": "è¾½å®", "å‰": "å‰æ—", "é»‘": "é»‘é¾™æ±Ÿ", "æ²ª": "ä¸Šæµ·", "è‹": "æ±Ÿè‹",
            "æµ™": "æµ™æ±Ÿ", "çš–": "å®‰å¾½", "é—½": "ç¦å»º", "èµ£": "æ±Ÿè¥¿", "é²": "å±±ä¸œ",
            "è±«": "æ²³å—", "é„‚": "æ¹–åŒ—", "æ¹˜": "æ¹–å—", "ç²¤": "å¹¿ä¸œ", "æ¡‚": "å¹¿è¥¿",
            "ç¼": "æµ·å—", "æ¸": "é‡åº†", "å·": "å››å·", "èœ€": "å››å·", "é»”": "è´µå·",
            "è´µ": "è´µå·", "æ»‡": "äº‘å—", "äº‘": "äº‘å—", "è—": "è¥¿è—", "é™•": "é™•è¥¿",
            "ç§¦": "é™•è¥¿", "ç”˜": "ç”˜è‚ƒ", "é™‡": "ç”˜è‚ƒ", "é’": "é’æµ·", "å®": "å®å¤",
            "æ–°": "æ–°ç–†"
        }
        
        # ç›®æ ‡å…³é”®è¯ï¼ˆç”¨äºæå–å’Œåˆ†ç±»ï¼‰
        self.target_keywords = [
            "ç›®æ ‡", "ä»»åŠ¡", "é‡ç‚¹", "è®¡åˆ’", "è§„åˆ’", "å·¥ç¨‹", "é¡¹ç›®", "ä¸¾æª",
            "æ¨è¿›", "å‘å±•", "å»ºè®¾", "å®Œå–„", "æå‡", "å¢é•¿", "å®ç°", "è¾¾åˆ°"
        ]
        
        logger.info("ğŸ“Š ç»“æœèšåˆå™¨åˆå§‹åŒ–å®Œæˆ")
    
    def aggregate_batch_results(self, batch_results: List[Dict[str, Any]], 
                              output_format: str = "province_list") -> AggregatedResult:
        """
        èšåˆæ‰¹æ¬¡ç»“æœ
        
        Args:
            batch_results: æ‰¹æ¬¡ç»“æœåˆ—è¡¨
            output_format: è¾“å‡ºæ ¼å¼
            
        Returns:
            AggregatedResult: èšåˆåçš„ç»“æœ
        """
        logger.info(f"ğŸ”„ å¼€å§‹èšåˆ {len(batch_results)} ä¸ªæ‰¹æ¬¡ç»“æœ")
        
        # æå–æ‰€æœ‰æˆåŠŸçš„ç»“æœ
        successful_results = [r for r in batch_results if r.get("success", False)]
        
        if not successful_results:
            return AggregatedResult(
                content="æŠ±æ­‰ï¼Œæ²¡æœ‰è·å–åˆ°æœ‰æ•ˆçš„æŸ¥è¯¢ç»“æœã€‚",
                provinces=[],
                total_targets=0,
                format_type=output_format,
                processing_stats={"success_rate": 0, "total_batches": len(batch_results)}
            )
        
        # è§£æå’Œæ ‡å‡†åŒ–çœä»½ä¿¡æ¯
        all_provinces = set()
        province_contents = {}
        
        for result in successful_results:
            content = result.get("content", "")
            provinces = result.get("provinces", [])
            
            # è§£æå†…å®¹ä¸­çš„çœä»½ä¿¡æ¯
            parsed_info = self._parse_province_content(content)
            
            for province, targets in parsed_info.items():
                normalized_province = self._normalize_province_name(province)
                if normalized_province:
                    all_provinces.add(normalized_province)
                    
                    if normalized_province not in province_contents:
                        province_contents[normalized_province] = []
                    
                    province_contents[normalized_province].extend(targets)
        
        # å»é‡å’Œä¼˜åŒ–å†…å®¹
        for province in province_contents:
            province_contents[province] = self._deduplicate_targets(province_contents[province])
        
        # æ ¹æ®æ ¼å¼è¦æ±‚ç”Ÿæˆæœ€ç»ˆç»“æœ
        if output_format == "province_list":
            final_content = self._format_as_province_list(province_contents)
        elif output_format == "detailed":
            final_content = self._format_as_detailed_report(province_contents)
        elif output_format == "comparison":
            final_content = self._format_as_comparison_table(province_contents)
        elif output_format == "statistics":
            final_content = self._format_as_statistics(province_contents)
        else:
            final_content = self._format_as_province_list(province_contents)
        
        # ç»Ÿè®¡ä¿¡æ¯
        total_targets = sum(len(targets) for targets in province_contents.values())
        
        processing_stats = {
            "success_rate": len(successful_results) / len(batch_results),
            "total_batches": len(batch_results),
            "successful_batches": len(successful_results),
            "provinces_found": len(all_provinces),
            "total_targets_extracted": total_targets
        }
        
        logger.info(f"âœ… èšåˆå®Œæˆ: {len(all_provinces)} ä¸ªçœä»½, {total_targets} ä¸ªç›®æ ‡")
        
        return AggregatedResult(
            content=final_content,
            provinces=sorted(list(all_provinces)),
            total_targets=total_targets,
            format_type=output_format,
            processing_stats=processing_stats
        )
    
    def _parse_province_content(self, content: str) -> Dict[str, List[str]]:
        """
        è§£æå†…å®¹ä¸­çš„çœä»½å’Œç›®æ ‡ä¿¡æ¯
        
        Args:
            content: åŸå§‹å†…å®¹
            
        Returns:
            Dict[str, List[str]]: çœä»½åˆ°ç›®æ ‡åˆ—è¡¨çš„æ˜ å°„
        """
        province_info = {}
        
        # æŒ‰è¡Œåˆ†å‰²å†…å®¹
        lines = content.split('\n')
        current_province = None
        
        for line in lines:
            line = line.strip()
            if not line:
                continue
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯çœä»½æ ‡é¢˜è¡Œ
            province_match = self._extract_province_from_line(line)
            if province_match:
                current_province = province_match
                if current_province not in province_info:
                    province_info[current_province] = []
                
                # æå–åŒè¡Œçš„ç›®æ ‡ä¿¡æ¯
                targets_in_line = self._extract_targets_from_line(line)
                if targets_in_line:
                    province_info[current_province].extend(targets_in_line)
            
            elif current_province:
                # å½“å‰è¡Œå±äºæŸä¸ªçœä»½çš„å†…å®¹
                targets_in_line = self._extract_targets_from_line(line)
                if targets_in_line:
                    province_info[current_province].extend(targets_in_line)
        
        return province_info
    
    def _extract_province_from_line(self, line: str) -> str:
        """ä»è¡Œä¸­æå–çœä»½åç§°"""
        from config.config import PROVINCES
        
        # æ£€æŸ¥æ ‡å‡†çœä»½åç§°
        for province in PROVINCES:
            if province in line:
                return province
        
        # æ£€æŸ¥çœä»½åˆ«å
        for alias, full_name in self.province_aliases.items():
            if alias in line:
                return full_name
        
        # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…çœä»½æ¨¡å¼
        province_pattern = r'([^ï¼š:]+)(?:çœ|å¸‚|è‡ªæ²»åŒº)?[ï¼š:]'
        match = re.search(province_pattern, line)
        if match:
            potential_province = match.group(1).strip()
            # éªŒè¯æ˜¯å¦æ˜¯æœ‰æ•ˆçš„çœä»½åç§°
            for province in PROVINCES:
                if province in potential_province or potential_province in province:
                    return province
        
        return None
    
    def _extract_targets_from_line(self, line: str) -> List[str]:
        """ä»è¡Œä¸­æå–ç›®æ ‡ä¿¡æ¯"""
        targets = []
        
        # ç§»é™¤çœä»½åç§°å‰ç¼€
        clean_line = line
        for province in ["åŒ—äº¬", "å¤©æ´¥", "æ²³åŒ—", "å±±è¥¿", "å†…è’™å¤", "è¾½å®", "å‰æ—", "é»‘é¾™æ±Ÿ",
                        "ä¸Šæµ·", "æ±Ÿè‹", "æµ™æ±Ÿ", "å®‰å¾½", "ç¦å»º", "æ±Ÿè¥¿", "å±±ä¸œ", "æ²³å—",
                        "æ¹–åŒ—", "æ¹–å—", "å¹¿ä¸œ", "å¹¿è¥¿", "æµ·å—", "é‡åº†", "å››å·", "è´µå·",
                        "äº‘å—", "è¥¿è—", "é™•è¥¿", "ç”˜è‚ƒ", "é’æµ·", "å®å¤", "æ–°ç–†"]:
            clean_line = re.sub(f'^{province}[ï¼š:]?', '', clean_line)
        
        # æŒ‰åˆ†éš”ç¬¦åˆ†å‰²ç›®æ ‡
        separators = ['ã€', 'ï¼Œ', ',', 'ï¼›', ';', 'ã€‚', '|']
        
        for sep in separators:
            if sep in clean_line:
                parts = clean_line.split(sep)
                for part in parts:
                    part = part.strip()
                    if part and len(part) > 3:  # è¿‡æ»¤å¤ªçŸ­çš„å†…å®¹
                        targets.append(part)
                break
        else:
            # æ²¡æœ‰æ‰¾åˆ°åˆ†éš”ç¬¦ï¼Œæ•´è¡Œä½œä¸ºä¸€ä¸ªç›®æ ‡
            clean_line = clean_line.strip()
            if clean_line and len(clean_line) > 3:
                targets.append(clean_line)
        
        # è¿‡æ»¤å’Œæ¸…ç†ç›®æ ‡
        cleaned_targets = []
        for target in targets:
            target = re.sub(r'^[0-9]+\.?\s*', '', target)  # ç§»é™¤åºå·
            target = target.strip()
            
            # æ£€æŸ¥æ˜¯å¦åŒ…å«ç›®æ ‡å…³é”®è¯
            if any(keyword in target for keyword in self.target_keywords) or len(target) > 10:
                cleaned_targets.append(target)
        
        return cleaned_targets
    
    def _normalize_province_name(self, province: str) -> str:
        """æ ‡å‡†åŒ–çœä»½åç§°"""
        if not province:
            return None
        
        # ç§»é™¤å¸¸è§åç¼€
        province = re.sub(r'(çœ|å¸‚|è‡ªæ²»åŒº|ç‰¹åˆ«è¡Œæ”¿åŒº)$', '', province)
        
        # æ£€æŸ¥åˆ«åæ˜ å°„
        if province in self.province_aliases:
            return self.province_aliases[province]
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯æ ‡å‡†çœä»½åç§°
        from config.config import PROVINCES
        for std_province in PROVINCES:
            if province == std_province or province in std_province:
                return std_province
        
        return province
    
    def _deduplicate_targets(self, targets: List[str]) -> List[str]:
        """å»é‡å’Œä¼˜åŒ–ç›®æ ‡åˆ—è¡¨"""
        if not targets:
            return []
        
        # å»é™¤å®Œå…¨é‡å¤çš„é¡¹
        unique_targets = list(dict.fromkeys(targets))
        
        # å»é™¤é«˜åº¦ç›¸ä¼¼çš„é¡¹
        final_targets = []
        for target in unique_targets:
            is_duplicate = False
            for existing in final_targets:
                # è®¡ç®—ç›¸ä¼¼åº¦
                if self._calculate_similarity(target, existing) > 0.8:
                    is_duplicate = True
                    # ä¿ç•™æ›´é•¿çš„ç‰ˆæœ¬
                    if len(target) > len(existing):
                        final_targets.remove(existing)
                        final_targets.append(target)
                    break
            
            if not is_duplicate:
                final_targets.append(target)
        
        return final_targets
    
    def _calculate_similarity(self, text1: str, text2: str) -> float:
        """è®¡ç®—ä¸¤ä¸ªæ–‡æœ¬çš„ç›¸ä¼¼åº¦"""
        # ç®€å•çš„å­—ç¬¦çº§ç›¸ä¼¼åº¦è®¡ç®—
        if not text1 or not text2:
            return 0.0
        
        # è®¡ç®—å…¬å…±å­—ç¬¦æ•°
        common_chars = sum(1 for c in text1 if c in text2)
        max_length = max(len(text1), len(text2))
        
        return common_chars / max_length if max_length > 0 else 0.0
    
    def _format_as_province_list(self, province_contents: Dict[str, List[str]]) -> str:
        """æ ¼å¼åŒ–ä¸ºçœä»½åˆ—è¡¨æ ¼å¼"""
        lines = []
        
        for province in sorted(province_contents.keys()):
            targets = province_contents[province]
            if targets:
                targets_str = "ã€".join(targets[:5])  # é™åˆ¶æ¯ä¸ªçœä»½æœ€å¤š5ä¸ªç›®æ ‡
                if len(targets) > 5:
                    targets_str += f"ç­‰{len(targets)}é¡¹"
                lines.append(f"{province}ï¼š{targets_str}")
            else:
                lines.append(f"{province}ï¼šä¿¡æ¯ä¸è¶³")
        
        return "\n".join(lines)
    
    def _format_as_detailed_report(self, province_contents: Dict[str, List[str]]) -> str:
        """æ ¼å¼åŒ–ä¸ºè¯¦ç»†æŠ¥å‘Šæ ¼å¼"""
        sections = []
        
        sections.append("# å„çœæ”¿åºœå·¥ä½œæŠ¥å‘Šä¸»è¦ç›®æ ‡æ±‡æ€»\n")
        
        for province in sorted(province_contents.keys()):
            targets = province_contents[province]
            sections.append(f"## {province}")
            
            if targets:
                for i, target in enumerate(targets, 1):
                    sections.append(f"{i}. {target}")
            else:
                sections.append("æš‚æ— å…·ä½“ç›®æ ‡ä¿¡æ¯")
            
            sections.append("")  # ç©ºè¡Œåˆ†éš”
        
        return "\n".join(sections)
    
    def _format_as_comparison_table(self, province_contents: Dict[str, List[str]]) -> str:
        """æ ¼å¼åŒ–ä¸ºå¯¹æ¯”è¡¨æ ¼æ ¼å¼"""
        lines = []
        lines.append("| çœä»½ | ä¸»è¦å·¥ä½œç›®æ ‡ | ç›®æ ‡æ•°é‡ |")
        lines.append("|------|-------------|---------|")
        
        for province in sorted(province_contents.keys()):
            targets = province_contents[province]
            target_count = len(targets)
            
            if targets:
                main_targets = "ã€".join(targets[:3])
                if len(targets) > 3:
                    main_targets += "..."
            else:
                main_targets = "ä¿¡æ¯ä¸è¶³"
                target_count = 0
            
            lines.append(f"| {province} | {main_targets} | {target_count} |")
        
        return "\n".join(lines)
    
    def _format_as_statistics(self, province_contents: Dict[str, List[str]]) -> str:
        """æ ¼å¼åŒ–ä¸ºç»Ÿè®¡ä¿¡æ¯æ ¼å¼"""
        total_provinces = len(province_contents)
        total_targets = sum(len(targets) for targets in province_contents.values())
        provinces_with_targets = sum(1 for targets in province_contents.values() if targets)
        
        # ç›®æ ‡ç±»å‹ç»Ÿè®¡
        target_types = {}
        for targets in province_contents.values():
            for target in targets:
                for keyword in self.target_keywords:
                    if keyword in target:
                        target_types[keyword] = target_types.get(keyword, 0) + 1
        
        lines = []
        lines.append("# æ”¿åºœå·¥ä½œæŠ¥å‘Šç»Ÿè®¡åˆ†æ")
        lines.append("")
        lines.append("## åŸºæœ¬ç»Ÿè®¡")
        lines.append(f"- æ€»çœä»½æ•°ï¼š{total_provinces}")
        lines.append(f"- æœ‰ç›®æ ‡ä¿¡æ¯çš„çœä»½ï¼š{provinces_with_targets}")
        lines.append(f"- æ€»ç›®æ ‡æ•°é‡ï¼š{total_targets}")
        lines.append(f"- å¹³å‡æ¯çœç›®æ ‡æ•°ï¼š{total_targets/total_provinces:.1f}")
        lines.append("")
        
        if target_types:
            lines.append("## ç›®æ ‡ç±»å‹åˆ†å¸ƒ")
            sorted_types = sorted(target_types.items(), key=lambda x: x[1], reverse=True)
            for target_type, count in sorted_types[:10]:
                lines.append(f"- {target_type}ï¼š{count} æ¬¡")
        
        return "\n".join(lines)
    
    def optimize_for_token_limit(self, content: str, max_tokens: int = 4000) -> str:
        """
        ä¼˜åŒ–å†…å®¹ä»¥é€‚åº”tokené™åˆ¶
        
        Args:
            content: åŸå§‹å†…å®¹
            max_tokens: æœ€å¤§tokenæ•°ï¼ˆç²—ç•¥ä¼°ç®—ï¼‰
            
        Returns:
            str: ä¼˜åŒ–åçš„å†…å®¹
        """
        # ç²—ç•¥ä¼°ç®—ï¼š1ä¸ªtokençº¦ç­‰äº1.5ä¸ªä¸­æ–‡å­—ç¬¦
        max_chars = max_tokens * 1.5
        
        if len(content) <= max_chars:
            return content
        
        logger.info(f"ğŸ”§ ä¼˜åŒ–å†…å®¹é•¿åº¦: {len(content)} -> {max_chars} å­—ç¬¦")
        
        # æŒ‰è¡Œåˆ†å‰²å¹¶ä¿ç•™é‡è¦ä¿¡æ¯
        lines = content.split('\n')
        optimized_lines = []
        current_chars = 0
        
        # ä¼˜å…ˆä¿ç•™çœä»½æ ‡é¢˜è¡Œ
        for line in lines:
            if any(province in line for province in ["åŒ—äº¬", "å¤©æ´¥", "æ²³åŒ—", "å±±è¥¿", "å†…è’™å¤", 
                                                   "è¾½å®", "å‰æ—", "é»‘é¾™æ±Ÿ", "ä¸Šæµ·", "æ±Ÿè‹", 
                                                   "æµ™æ±Ÿ", "å®‰å¾½", "ç¦å»º", "æ±Ÿè¥¿", "å±±ä¸œ", 
                                                   "æ²³å—", "æ¹–åŒ—", "æ¹–å—", "å¹¿ä¸œ", "å¹¿è¥¿", 
                                                   "æµ·å—", "é‡åº†", "å››å·", "è´µå·", "äº‘å—", 
                                                   "è¥¿è—", "é™•è¥¿", "ç”˜è‚ƒ", "é’æµ·", "å®å¤", "æ–°ç–†"]):
                if current_chars + len(line) <= max_chars:
                    optimized_lines.append(line)
                    current_chars += len(line) + 1  # +1 for newline
                else:
                    # æˆªæ–­æœ€åä¸€è¡Œ
                    remaining_chars = max_chars - current_chars
                    if remaining_chars > 10:
                        optimized_lines.append(line[:remaining_chars] + "...")
                    break
        
        return '\n'.join(optimized_lines)

# å…¨å±€ç»“æœèšåˆå™¨å®ä¾‹
_result_aggregator = None

def get_result_aggregator() -> ResultAggregator:
    """è·å–å…¨å±€ç»“æœèšåˆå™¨å®ä¾‹"""
    global _result_aggregator
    if _result_aggregator is None:
        _result_aggregator = ResultAggregator()
    return _result_aggregator

 