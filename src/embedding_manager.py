#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
Jina Embeddings v4 æ¨¡å‹ç®¡ç†å™¨
è´Ÿè´£æ¨¡å‹ä¸‹è½½ã€åŠ è½½å’Œæ–‡æœ¬å‘é‡åŒ–
"""

import os
import numpy as np
from typing import List, Union
from pathlib import Path
import torch
from transformers import AutoModel
from tqdm import tqdm
import logging

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class JinaEmbeddingManager:
    """Jina Embeddings v4 æ¨¡å‹ç®¡ç†å™¨"""
    
    def __init__(self, model_name: str = "jinaai/jina-embeddings-v4", 
                 cache_dir: str = None, device: str = None):
        """
        åˆå§‹åŒ–Jina Embeddingç®¡ç†å™¨
        
        Args:
            model_name: æ¨¡å‹åç§°
            cache_dir: ç¼“å­˜ç›®å½•
            device: è®¾å¤‡ç±»å‹ ('cuda', 'cpu', Noneè‡ªåŠ¨é€‰æ‹©)
        """
        self.model_name = model_name
        
        # ä½¿ç”¨é¡¹ç›®æœ¬åœ°çš„ç¼“å­˜ç›®å½•
        if cache_dir is None:
            from config.config import EMBEDDING_CONFIG
            self.cache_dir = str(EMBEDDING_CONFIG["model_path"])
        else:
            self.cache_dir = cache_dir
        
        # è‡ªåŠ¨é€‰æ‹©è®¾å¤‡ - ä¼˜å…ˆä½¿ç”¨GPU
        if device is None:
            self.device = "cuda" if torch.cuda.is_available() else "cpu"
        else:
            self.device = device
            
        self.model = None
        
        logger.info(f"ğŸš€ åˆå§‹åŒ–Jina Embeddingç®¡ç†å™¨")
        logger.info(f"ğŸ“± è®¾å¤‡: {self.device}")
        if self.device == "cuda":
            logger.info(f"ğŸ® GPU: {torch.cuda.get_device_name(0)}")
        logger.info(f"ğŸ”¤ æ¨¡å‹: {model_name}")
        logger.info(f"ğŸ“ ç¼“å­˜ç›®å½•: {self.cache_dir}")
    
    def download_and_load_model(self) -> bool:
        """
        ä¸‹è½½å¹¶åŠ è½½æ¨¡å‹
        
        Returns:
            bool: æ˜¯å¦æˆåŠŸåŠ è½½
        """
        try:
            logger.info(f"ğŸ“¥ å¼€å§‹åŠ è½½æ¨¡å‹: {self.model_name}")
            
            # è®¾ç½®ç¯å¢ƒå˜é‡å¼ºåˆ¶ç¦ç”¨FlashAttention
            os.environ['FLASH_ATTENTION_FORCE_DISABLE'] = '1'
            
            # ä½¿ç”¨å®˜æ–¹æ¨èçš„æ–¹å¼åŠ è½½æ¨¡å‹
            self.model = AutoModel.from_pretrained(
                self.model_name,
                trust_remote_code=True,
                cache_dir=self.cache_dir,
                attn_implementation="eager"  # å¼ºåˆ¶ä½¿ç”¨eager attention
            )
            
            # ç§»åŠ¨åˆ°æŒ‡å®šè®¾å¤‡
            self.model = self.model.to(self.device)
            self.model.eval()  # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
            
            logger.info(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸï¼")
            logger.info(f"ğŸ“Š æ¨¡å‹å‚æ•°é‡: {sum(p.numel() for p in self.model.parameters()):,}")
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}")
            return False
    
    def encode_texts(self, texts: Union[str, List[str]], 
                    task: str = "retrieval",
                    prompt_name: str = "passage",
                    batch_size: int = 32, 
                    show_progress: bool = True) -> np.ndarray:
        """
        å°†æ–‡æœ¬ç¼–ç ä¸ºå‘é‡ - ä½¿ç”¨å®˜æ–¹API
        
        Args:
            texts: å•ä¸ªæ–‡æœ¬æˆ–æ–‡æœ¬åˆ—è¡¨
            task: ä»»åŠ¡ç±»å‹ ("retrieval", "text-matching", "code")
            prompt_name: æç¤ºåç§° ("query", "passage")
            batch_size: æ‰¹å¤„ç†å¤§å°
            show_progress: æ˜¯å¦æ˜¾ç¤ºè¿›åº¦æ¡
            
        Returns:
            np.ndarray: æ–‡æœ¬å‘é‡æ•°ç»„
        """
        if self.model is None:
            raise ValueError("æ¨¡å‹æœªåŠ è½½ï¼Œè¯·å…ˆè°ƒç”¨ download_and_load_model()")
        
        # å¤„ç†å•ä¸ªæ–‡æœ¬çš„æƒ…å†µ
        if isinstance(texts, str):
            texts = [texts]
        
        embeddings = []
        
        # æ‰¹å¤„ç†ç¼–ç 
        batches = [texts[i:i + batch_size] for i in range(0, len(texts), batch_size)]
        
        with torch.no_grad():
            for batch in tqdm(batches, desc="ğŸ”„ ç¼–ç æ–‡æœ¬", disable=not show_progress):
                try:
                    # ä½¿ç”¨å®˜æ–¹APIè¿›è¡Œç¼–ç 
                    batch_embeddings = self.model.encode_text(
                        texts=batch,
                        task=task,
                        prompt_name=prompt_name
                    )
                    
                    # encode_textè¿”å›çš„æ˜¯listï¼Œéœ€è¦å¤„ç†æ¯ä¸ªå…ƒç´ 
                    if isinstance(batch_embeddings, list):
                        # è½¬æ¢listä¸­çš„æ¯ä¸ªtensor
                        numpy_batch = []
                        for emb in batch_embeddings:
                            if isinstance(emb, torch.Tensor):
                                numpy_batch.append(emb.detach().cpu().numpy())
                            else:
                                numpy_batch.append(emb)
                        batch_embeddings = np.array(numpy_batch)
                    elif isinstance(batch_embeddings, torch.Tensor):
                        batch_embeddings = batch_embeddings.detach().cpu().numpy()
                    
                    embeddings.append(batch_embeddings)
                    
                except Exception as e:
                    logger.error(f"âŒ æ‰¹æ¬¡ç¼–ç å¤±è´¥: {str(e)}")
                    raise
        
        # åˆå¹¶æ‰€æœ‰æ‰¹æ¬¡çš„ç»“æœ
        if embeddings:
            # ç¡®ä¿æ‰€æœ‰embeddingséƒ½æ˜¯numpyæ•°ç»„
            numpy_embeddings = []
            for emb in embeddings:
                if isinstance(emb, torch.Tensor):
                    numpy_embeddings.append(emb.cpu().numpy())
                else:
                    numpy_embeddings.append(emb)
            
            result = np.vstack(numpy_embeddings)
            logger.info(f"âœ… ç¼–ç å®Œæˆï¼Œå½¢çŠ¶: {result.shape}")
            return result
        else:
            raise ValueError("ç¼–ç å¤±è´¥ï¼Œæ²¡æœ‰ç”Ÿæˆä»»ä½•å‘é‡")
    
    def encode_query(self, query: str) -> np.ndarray:
        """
        ç¼–ç æŸ¥è¯¢æ–‡æœ¬
        
        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            
        Returns:
            np.ndarray: æŸ¥è¯¢å‘é‡
        """
        return self.encode_texts(
            texts=[query],
            task="retrieval",
            prompt_name="query",
            show_progress=False
        )[0]
    
    def encode_passages(self, passages: List[str], 
                       batch_size: int = 32,
                       show_progress: bool = True) -> np.ndarray:
        """
        ç¼–ç æ–‡æ¡£æ®µè½
        
        Args:
            passages: æ–‡æ¡£æ®µè½åˆ—è¡¨
            batch_size: æ‰¹å¤„ç†å¤§å°
            show_progress: æ˜¯å¦æ˜¾ç¤ºè¿›åº¦æ¡
            
        Returns:
            np.ndarray: æ–‡æ¡£å‘é‡æ•°ç»„
        """
        return self.encode_texts(
            texts=passages,
            task="retrieval", 
            prompt_name="passage",
            batch_size=batch_size,
            show_progress=show_progress
        )
    
    def encode_for_matching(self, texts: List[str],
                           batch_size: int = 32,
                           show_progress: bool = True) -> np.ndarray:
        """
        ç¼–ç æ–‡æœ¬ç”¨äºåŒ¹é…ä»»åŠ¡
        
        Args:
            texts: æ–‡æœ¬åˆ—è¡¨
            batch_size: æ‰¹å¤„ç†å¤§å°
            show_progress: æ˜¯å¦æ˜¾ç¤ºè¿›åº¦æ¡
            
        Returns:
            np.ndarray: æ–‡æœ¬å‘é‡æ•°ç»„
        """
        return self.encode_texts(
            texts=texts,
            task="text-matching",
            batch_size=batch_size,
            show_progress=show_progress
        )
    
    def get_embedding_dimension(self) -> int:
        """
        è·å–å‘é‡ç»´åº¦
        
        Returns:
            int: å‘é‡ç»´åº¦
        """
        if self.model is None:
            raise ValueError("æ¨¡å‹æœªåŠ è½½")
        
        # ä½¿ç”¨ä¸€ä¸ªæµ‹è¯•æ–‡æœ¬è·å–ç»´åº¦
        test_embedding = self.encode_texts(
            texts=["test"], 
            task="retrieval", 
            prompt_name="passage",
            show_progress=False
        )
        return test_embedding.shape[1]
    
    def calculate_similarity(self, embedding1: np.ndarray, 
                           embedding2: np.ndarray) -> float:
        """
        è®¡ç®—ä¸¤ä¸ªå‘é‡çš„ä½™å¼¦ç›¸ä¼¼åº¦
        
        Args:
            embedding1: å‘é‡1
            embedding2: å‘é‡2
            
        Returns:
            float: ç›¸ä¼¼åº¦åˆ†æ•°
        """
        from sklearn.metrics.pairwise import cosine_similarity
        
        # ç¡®ä¿å‘é‡æ˜¯äºŒç»´çš„
        if embedding1.ndim == 1:
            embedding1 = embedding1.reshape(1, -1)
        if embedding2.ndim == 1:
            embedding2 = embedding2.reshape(1, -1)
            
        similarity = cosine_similarity(embedding1, embedding2)[0][0]
        return float(similarity)
    
    def is_model_loaded(self) -> bool:
        """æ£€æŸ¥æ¨¡å‹æ˜¯å¦å·²åŠ è½½"""
        return self.model is not None
    
    def get_model_info(self) -> dict:
        """è·å–æ¨¡å‹ä¿¡æ¯"""
        if self.model is None:
            return {"loaded": False}
        
        return {
            "loaded": True,
            "model_name": self.model_name,
            "device": self.device,
            "parameter_count": sum(p.numel() for p in self.model.parameters()),
            "embedding_dimension": self.get_embedding_dimension()
        }

def get_embedding_manager() -> JinaEmbeddingManager:
    """
    è·å–å…¨å±€çš„embeddingç®¡ç†å™¨å®ä¾‹
    
    Returns:
        JinaEmbeddingManager: embeddingç®¡ç†å™¨å®ä¾‹
    """
    if not hasattr(get_embedding_manager, '_instance'):
        get_embedding_manager._instance = JinaEmbeddingManager()
        
        # è‡ªåŠ¨åŠ è½½æ¨¡å‹
        if not get_embedding_manager._instance.download_and_load_model():
            raise RuntimeError("æ— æ³•åŠ è½½embeddingæ¨¡å‹")
    
    return get_embedding_manager._instance

 