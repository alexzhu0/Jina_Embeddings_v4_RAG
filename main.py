#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
æ”¿åºœå·¥ä½œæŠ¥å‘ŠRAGç³»ç»Ÿä¸»ç¨‹åº
è§£å†³çŸ¥è¯†åº“å†…å®¹è¿‡å¤šï¼Œæ¨¡å‹ä¸€æ¬¡æ€§è¿”å›ä¿¡æ¯æœ‰é™çš„é—®é¢˜
"""

import sys
import time
import logging
from pathlib import Path

# æ·»åŠ srcç›®å½•åˆ°è·¯å¾„
sys.path.append(str(Path(__file__).parent / "src"))

from config.config import ensure_directories
from src.data_processor import GovernmentReportProcessor
from src.vector_store import get_vector_store
from src.query_router import get_query_router
from src.result_aggregator import get_result_aggregator
from src.api_client import get_api_client

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('logs/government_rag.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class GovernmentReportRAG:
    """æ”¿åºœå·¥ä½œæŠ¥å‘ŠRAGç³»ç»Ÿä¸»ç±»"""
    
    def __init__(self):
        """åˆå§‹åŒ–RAGç³»ç»Ÿ"""
        logger.info("ğŸš€ åˆå§‹åŒ–æ”¿åºœå·¥ä½œæŠ¥å‘ŠRAGç³»ç»Ÿ...")
        
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        ensure_directories()
        
        # åˆå§‹åŒ–ç»„ä»¶
        self.vector_store = get_vector_store()
        self.query_router = get_query_router()
        self.result_aggregator = get_result_aggregator()
        self.api_client = get_api_client()
        
        # ç³»ç»ŸçŠ¶æ€
        self.is_ready = False
        
        logger.info("âœ… RAGç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
    
    def setup_system(self, force_rebuild: bool = False) -> bool:
        """
        è®¾ç½®ç³»ç»Ÿï¼ˆå¤„ç†æ–‡æ¡£ã€æ„å»ºç´¢å¼•ï¼‰
        
        Args:
            force_rebuild: æ˜¯å¦å¼ºåˆ¶é‡å»ºç´¢å¼•
            
        Returns:
            bool: æ˜¯å¦è®¾ç½®æˆåŠŸ
        """
        logger.info("ğŸ”§ å¼€å§‹è®¾ç½®ç³»ç»Ÿ...")
        
        try:
            # æ£€æŸ¥æ˜¯å¦éœ€è¦é‡å»ºç´¢å¼•
            if force_rebuild or not self.vector_store.is_built():
                logger.info("ğŸ“š éœ€è¦æ„å»ºå‘é‡ç´¢å¼•...")
                
                # åˆå§‹åŒ–æ–‡æ¡£å¤„ç†å™¨
                from config.config import DATA_PATHS, DOCUMENT_CONFIG
                processor = GovernmentReportProcessor(
                    raw_documents_path=DATA_PATHS["raw_documents"],
                    chunk_size=DOCUMENT_CONFIG["chunk_size"],
                    chunk_overlap=DOCUMENT_CONFIG["chunk_overlap"]
                )
                
                # å°è¯•åŠ è½½å·²å¤„ç†çš„æ•°æ®
                chunks = processor.load_processed_data(DATA_PATHS["processed_data"])
                
                if not chunks or force_rebuild:
                    logger.info("ğŸ“– å¤„ç†åŸå§‹æ–‡æ¡£...")
                    chunks = processor.process_all_documents()
                    
                    if not chunks:
                        logger.error("âŒ æ–‡æ¡£å¤„ç†å¤±è´¥ï¼Œæ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„æ–‡æ¡£")
                        return False
                    
                    # ä¿å­˜å¤„ç†ç»“æœ
                    processor.save_processed_data(chunks, DATA_PATHS["processed_data"])
                
                # æ„å»ºå‘é‡ç´¢å¼•
                logger.info("ğŸ”¨ æ„å»ºå‘é‡ç´¢å¼•...")
                if not self.vector_store.build_index(chunks):
                    logger.error("âŒ å‘é‡ç´¢å¼•æ„å»ºå¤±è´¥")
                    return False
                
                # ä¿å­˜ç´¢å¼•
                if not self.vector_store.save_index():
                    logger.error("âŒ å‘é‡ç´¢å¼•ä¿å­˜å¤±è´¥")
                    return False
            
            else:
                logger.info("ğŸ“‚ åŠ è½½å·²æœ‰çš„å‘é‡ç´¢å¼•...")
                if not self.vector_store.load_index():
                    logger.error("âŒ å‘é‡ç´¢å¼•åŠ è½½å¤±è´¥")
                    return False
            
            # æµ‹è¯•APIè¿æ¥
            logger.info("ğŸ” æµ‹è¯•APIè¿æ¥...")
            if not self.api_client.test_connection():
                logger.error("âŒ APIè¿æ¥æµ‹è¯•å¤±è´¥")
                return False
            
            self.is_ready = True
            logger.info("âœ… ç³»ç»Ÿè®¾ç½®å®Œæˆï¼Œå¯ä»¥å¼€å§‹æŸ¥è¯¢")
            
            # æ˜¾ç¤ºç³»ç»Ÿç»Ÿè®¡ä¿¡æ¯
            stats = self.vector_store.get_statistics()
            logger.info(f"ğŸ“Š ç³»ç»Ÿç»Ÿè®¡: {stats}")
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ ç³»ç»Ÿè®¾ç½®å¤±è´¥: {str(e)}")
            return False
    
    def query(self, user_query: str) -> dict:
        """
        å¤„ç†ç”¨æˆ·æŸ¥è¯¢
        
        Args:
            user_query: ç”¨æˆ·æŸ¥è¯¢æ–‡æœ¬
            
        Returns:
            dict: æŸ¥è¯¢ç»“æœ
        """
        if not self.is_ready:
            return {
                "success": False,
                "error": "ç³»ç»Ÿæœªå°±ç»ªï¼Œè¯·å…ˆè¿è¡Œsetup_system()",
                "content": ""
            }
        
        logger.info(f"ğŸ” å¤„ç†æŸ¥è¯¢: {user_query}")
        start_time = time.time()
        
        try:
            # 1. åˆ†ææŸ¥è¯¢æ„å›¾
            query_analysis = self.query_router.analyze_query(user_query)
            logger.info(f"ğŸ¯ æŸ¥è¯¢åˆ†æ: {query_analysis['intent']['type']}")
            
            # 2. åˆ›å»ºæŸ¥è¯¢è®¡åˆ’
            query_plan = self.query_router.create_query_plan(query_analysis)
            logger.info(f"ğŸ“‹ æŸ¥è¯¢è®¡åˆ’: {query_plan.batch_strategy} ({len(query_plan.batches)} æ‰¹æ¬¡)")
            
            # 3. æ‰§è¡ŒæŸ¥è¯¢è®¡åˆ’
            execution_result = self.query_router.execute_query_plan(query_plan)
            
            if not execution_result["success"]:
                return {
                    "success": False,
                    "error": "æŸ¥è¯¢æ‰§è¡Œå¤±è´¥",
                    "content": execution_result.get("content", ""),
                    "processing_time": time.time() - start_time
                }
            
            # 4. èšåˆç»“æœ
            if len(query_plan.batches) > 1:
                logger.info("ğŸ“Š èšåˆå¤šæ‰¹æ¬¡ç»“æœ...")
                aggregated_result = self.result_aggregator.aggregate_batch_results(
                    execution_result["batch_results"],
                    query_plan.output_format
                )
                final_content = aggregated_result.content
                provinces = aggregated_result.provinces
                processing_stats = aggregated_result.processing_stats
            else:
                final_content = execution_result["content"]
                provinces = execution_result.get("provinces", [])
                processing_stats = {
                    "success_rate": 1.0,
                    "total_batches": 1,
                    "successful_batches": 1
                }
            
            # 5. ä¼˜åŒ–è¾“å‡ºé•¿åº¦
            if len(final_content) > 6000:  # å¦‚æœå†…å®¹è¿‡é•¿
                final_content = self.result_aggregator.optimize_for_token_limit(
                    final_content, max_tokens=4000
                )
            
            processing_time = time.time() - start_time
            
            logger.info(f"âœ… æŸ¥è¯¢å®Œæˆ ({processing_time:.2f}s): {len(provinces)} ä¸ªçœä»½")
            
            return {
                "success": True,
                "content": final_content,
                "provinces": provinces,
                "query_type": query_analysis["intent"]["type"],
                "output_format": query_plan.output_format,
                "processing_time": processing_time,
                "processing_stats": processing_stats,
                "query_plan": {
                    "strategy": query_plan.batch_strategy,
                    "batches": len(query_plan.batches)
                }
            }
            
        except Exception as e:
            logger.error(f"âŒ æŸ¥è¯¢å¤„ç†å¼‚å¸¸: {str(e)}")
            return {
                "success": False,
                "error": str(e),
                "content": "",
                "processing_time": time.time() - start_time
            }
    
    def get_system_status(self) -> dict:
        """è·å–ç³»ç»ŸçŠ¶æ€ä¿¡æ¯"""
        status = {
            "is_ready": self.is_ready,
            "vector_store_built": self.vector_store.is_built() if self.vector_store else False,
            "api_available": False
        }
        
        if self.vector_store and self.vector_store.is_built():
            status["vector_stats"] = self.vector_store.get_statistics()
        
        # æµ‹è¯•APIå¯ç”¨æ€§
        try:
            if self.api_client:
                status["api_available"] = self.api_client.test_connection()
        except:
            status["api_available"] = False
        
        return status

def main():
    """ä¸»å‡½æ•° - å‘½ä»¤è¡Œäº¤äº’ç•Œé¢"""
    print("ğŸ›ï¸ æ”¿åºœå·¥ä½œæŠ¥å‘ŠRAGç³»ç»Ÿ")
    print("=" * 50)
    
    # åˆå§‹åŒ–ç³»ç»Ÿ
    rag_system = GovernmentReportRAG()
    
    # è®¾ç½®ç³»ç»Ÿ
    print("\nğŸ”§ æ­£åœ¨è®¾ç½®ç³»ç»Ÿ...")
    if not rag_system.setup_system():
        print("âŒ ç³»ç»Ÿè®¾ç½®å¤±è´¥ï¼Œè¯·æ£€æŸ¥é…ç½®å’Œæ•°æ®")
        return
    
    print("\nâœ… ç³»ç»Ÿå°±ç»ªï¼å¯ä»¥å¼€å§‹æŸ¥è¯¢")
    print("\nğŸ’¡ ç¤ºä¾‹æŸ¥è¯¢:")
    print("  - åˆ—å‡ºå„çœçš„ä¸»è¦å·¥ä½œç›®æ ‡")
    print("  - åŒ—äº¬å¸‚çš„ç»æµå‘å±•é‡ç‚¹æ˜¯ä»€ä¹ˆ")
    print("  - å¯¹æ¯”å¹¿ä¸œå’Œæ±Ÿè‹çš„äº§ä¸šå‘å±•")
    print("  - ç»Ÿè®¡å„çœçš„ç¯å¢ƒä¿æŠ¤æªæ–½")
    print("\nè¾“å…¥ 'quit' æˆ– 'exit' é€€å‡ºç³»ç»Ÿ")
    print("-" * 50)
    
    # äº¤äº’å¾ªç¯
    while True:
        try:
            user_input = input("\nğŸ” è¯·è¾“å…¥æŸ¥è¯¢: ").strip()
            
            if user_input.lower() in ['quit', 'exit', 'é€€å‡º']:
                print("ğŸ‘‹ å†è§ï¼")
                break
            
            if not user_input:
                continue
            
            print(f"\nâ³ å¤„ç†ä¸­...")
            
            # æ‰§è¡ŒæŸ¥è¯¢
            result = rag_system.query(user_input)
            
            if result["success"]:
                print(f"\nğŸ“ æŸ¥è¯¢ç»“æœ:")
                print(f"ç±»å‹: {result.get('query_type', 'unknown')}")
                print(f"æ ¼å¼: {result.get('output_format', 'unknown')}")
                print(f"çœä»½æ•°: {len(result.get('provinces', []))}")
                print(f"å¤„ç†æ—¶é—´: {result.get('processing_time', 0):.2f}s")
                print("-" * 30)
                print(result["content"])
                
                # æ˜¾ç¤ºå¤„ç†ç»Ÿè®¡
                if "processing_stats" in result:
                    stats = result["processing_stats"]
                    print(f"\nğŸ“Š å¤„ç†ç»Ÿè®¡:")
                    print(f"æˆåŠŸç‡: {stats.get('success_rate', 0):.1%}")
                    print(f"æ‰¹æ¬¡: {stats.get('successful_batches', 0)}/{stats.get('total_batches', 0)}")
            else:
                print(f"\nâŒ æŸ¥è¯¢å¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
                if result.get('content'):
                    print(f"éƒ¨åˆ†ç»“æœ: {result['content']}")
        
        except KeyboardInterrupt:
            print("\n\nğŸ‘‹ ç”¨æˆ·ä¸­æ–­ï¼Œå†è§ï¼")
            break
        except Exception as e:
            print(f"\nâŒ ç³»ç»Ÿé”™è¯¯: {str(e)}")

if __name__ == "__main__":
    main() 